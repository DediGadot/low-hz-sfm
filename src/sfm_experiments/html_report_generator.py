#!/usr/bin/env python3
"""
HTML Report Generator for LaMAR Experiments

This module generates comprehensive HTML dashboard reports by consolidating
individual Plotly visualizations into a single, professional HTML document
using Jinja2 templates.

Third-party Dependencies:
- jinja2: https://jinja.palletsprojects.com/
- pandas: https://pandas.pydata.org/docs/

Sample Input:
    from pathlib import Path
    viz_paths = VisualizationPaths(...)
    summary_df = create_summary_dataframe(results)
    generate_comprehensive_report(viz_paths, summary_df, output_path)

Expected Output:
    Single HTML file with embedded interactive visualizations
"""

import re
import sys
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

import pandas as pd
from jinja2 import Environment, FileSystemLoader, select_autoescape
from loguru import logger


def extract_plotly_content(html_file: Path) -> str:
    """
    Extract Plotly visualization content from HTML file.

    Reads an HTML file generated by Plotly and extracts the div and script
    elements containing the interactive visualization, ready to be embedded
    in another HTML document. Strips out the embedded Plotly.js library to
    reduce file size (library is loaded via CDN in the main template).

    Args:
        html_file: Path to Plotly-generated HTML file

    Returns:
        HTML string containing div and script elements (without embedded library)
    """
    try:
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # Extract the plotly div (contains the visualization container)
        div_match = re.search(
            r'<div\s+id=["\'][\w-]+["\']\s+class=["\']plotly-graph-div["\'].*?>.*?</div>',
            content,
            re.DOTALL
        )

        # Extract ONLY the script tag that contains Plotly.newPlot (not the library)
        # This matches the script tag that has window.PLOTLYENV and Plotly.newPlot
        script_match = re.search(
            r'<script type=["\']text/javascript["\']>\s*(window\.PLOTLYENV.*?Plotly\.newPlot.*?)</script>',
            content,
            re.DOTALL
        )

        if div_match and script_match:
            # The script_match.group(1) already contains just the plot data, not the library
            plot_script = script_match.group(1)

            # Construct the minimal HTML with div and plot script only
            return div_match.group(0) + '\n' + f'<script type="text/javascript">{plot_script}</script>'

        # Fallback: return entire body content if pattern matching fails
        body_match = re.search(r'<body>(.*?)</body>', content, re.DOTALL)
        if body_match:
            logger.warning(f"Using fallback extraction method for {html_file.name}")
            return body_match.group(1)

        logger.error(f"Could not extract Plotly content from {html_file.name}")
        return f'<p>Error loading visualization from {html_file.name}</p>'

    except Exception as e:
        logger.error(f"Error reading {html_file}: {e}")
        return f'<p>Error: {e}</p>'


def collect_scene_visualizations(
    scene_name: str,
    scene_dir: Path
) -> Dict[str, str]:
    """
    Collect all visualization HTML content for a single scene.

    Args:
        scene_name: Name of the scene (e.g., 'CAB', 'HGE', 'LIN')
        scene_dir: Directory containing scene visualization files

    Returns:
        Dictionary mapping visualization type to HTML content
    """
    visualizations = {}

    # Define expected visualization files
    viz_files = {
        'point_cloud_3d': f"{scene_name}_point_cloud_3d.html",
        'point_density': f"{scene_name}_point_density.html",
        'track_length_hist': f"{scene_name}_track_length_hist.html",
        'reprojection_error_hist': f"{scene_name}_reprojection_error_hist.html",
        'camera_trajectory_3d': f"{scene_name}_camera_trajectory_3d.html",
        'camera_topdown': f"{scene_name}_camera_topdown_map.html",
        'camera_distribution': f"{scene_name}_camera_distribution.html",
    }

    for viz_type, filename in viz_files.items():
        filepath = scene_dir / filename
        if filepath.exists():
            visualizations[viz_type] = extract_plotly_content(filepath)
            logger.debug(f"  ✓ Extracted {viz_type} for {scene_name}")
        else:
            logger.warning(f"  ✗ Missing {filename} for {scene_name}")
            visualizations[viz_type] = f'<p>Visualization not available: {filename}</p>'

    return visualizations


def collect_comparison_visualizations(
    comparison_dir: Path
) -> Dict[str, str]:
    """
    Collect cross-scene comparison visualization HTML content.

    Args:
        comparison_dir: Directory containing comparison visualization files

    Returns:
        Dictionary mapping comparison type to HTML content
    """
    comparisons = {}

    comparison_files = {
        'scene_comparison': 'scene_comparison_bar_chart.html',
        'images_vs_points': 'images_vs_points_scatter.html',
        'quality_metrics': 'quality_metrics_comparison.html',
    }

    for comp_type, filename in comparison_files.items():
        filepath = comparison_dir / filename
        if filepath.exists():
            comparisons[comp_type] = extract_plotly_content(filepath)
            logger.debug(f"  ✓ Extracted {comp_type}")
        else:
            logger.warning(f"  ✗ Missing {filename}")
            comparisons[comp_type] = f'<p>Comparison not available: {filename}</p>'

    return comparisons


def prepare_summary_statistics(
    summary_df: pd.DataFrame
) -> List[Dict[str, any]]:
    """
    Convert summary DataFrame to list of dictionaries for template rendering.

    Extracts all comprehensive metrics from the DataFrame and formats them
    for display in the HTML template, including temporal coverage, spatial
    coverage, quality distribution, and efficiency metrics.

    Args:
        summary_df: pandas DataFrame with comprehensive scene statistics

    Returns:
        List of dictionaries, one per scene, with all metrics
    """
    if summary_df.empty:
        return []

    stats = []
    for _, row in summary_df.iterrows():
        stats.append({
            # Basic identification
            'scene_name': row.get('Scene', 'Unknown'),
            'num_images': int(row.get('Images', 0)),
            'num_points': int(row.get('3D Points', 0)),
            'num_cameras': int(row.get('Cameras', 0)),
            'execution_time': float(row.get('Time (s)', 0.0)),

            # Quality metrics
            'mean_track_length': float(row.get('Mean Track Length', 0.0)),
            'median_track_length': float(row.get('Median Track Length', 0.0)),
            'track_length_p95': float(row.get('Track Length P95', 0.0)),
            'mean_reproj_error': float(row.get('Mean Error (px)', 0.0)),
            'median_reproj_error': float(row.get('Median Error (px)', 0.0)),
            'reprojection_error_p95': float(row.get('Reprojection Error P95', 0.0)),
            'high_quality_points_pct': float(row.get('High Quality Points %', 0.0)),

            # Spatial coverage
            'spatial_extent_x': float(row.get('Spatial Extent X (m)', 0.0)),
            'spatial_extent_y': float(row.get('Spatial Extent Y (m)', 0.0)),
            'spatial_extent_z': float(row.get('Spatial Extent Z (m)', 0.0)),
            'scene_volume_m3': float(row.get('Scene Volume (m³)', 0.0)),
            'trajectory_length_m': float(row.get('Trajectory Length (m)', 0.0)),

            # Temporal coverage
            'capture_duration_s': float(row.get('Capture Duration (s)', 0.0)),
            'mean_capture_interval_s': float(row.get('Mean Capture Interval (s)', 0.0)),
            'capture_frequency_hz': float(row.get('Capture Frequency (Hz)', 0.0)),
            'num_images_with_timestamp': int(row.get('Images with Timestamp', 0)),

            # Efficiency metrics
            'points_per_image': float(row.get('Points per Image', 0.0)),
            'observations_per_image': float(row.get('Observations per Image', 0.0)),
        })

    return stats


def generate_comprehensive_report(
    viz_paths,  # VisualizationPaths from lamar_visualization.py
    summary_df: pd.DataFrame,
    output_path: Path
) -> Path:
    """
    Generate comprehensive HTML dashboard report.

    This function consolidates all individual Plotly visualizations into a
    single, professional HTML document with navigation, summary statistics,
    and embedded interactive plots.

    Args:
        viz_paths: VisualizationPaths object with paths to all visualizations
        summary_df: pandas DataFrame with scene statistics
        output_path: Path where the comprehensive report should be saved

    Returns:
        Path to the generated HTML report

    Raises:
        FileNotFoundError: If template directory doesn't exist
        RuntimeError: If report generation fails
    """
    logger.info("\n" + "="*80)
    logger.info("Generating Comprehensive HTML Dashboard Report")
    logger.info("="*80)

    # Setup Jinja2 environment
    template_dir = Path(__file__).parent / "templates"
    if not template_dir.exists():
        raise FileNotFoundError(f"Template directory not found: {template_dir}")

    env = Environment(
        loader=FileSystemLoader(template_dir),
        autoescape=select_autoescape(['html', 'xml'])
    )

    try:
        template = env.get_template("comprehensive_report.html.jinja2")
    except Exception as e:
        raise RuntimeError(f"Failed to load template: {e}")

    # Collect all visualizations
    logger.info("Extracting visualization content...")

    # Get scene names from scene_dirs
    scene_names = list(viz_paths.scene_dirs.keys())
    logger.info(f"Scenes: {', '.join(scene_names)}")

    # Collect comparison charts
    comparison_dir = viz_paths.output_dir / "comparisons"
    comparison_charts = collect_comparison_visualizations(comparison_dir)
    logger.info(f"  ✓ Collected {len(comparison_charts)} comparison charts")

    # Collect per-scene visualizations
    scene_visualizations = {}
    for scene_name, scene_dir in viz_paths.scene_dirs.items():
        logger.info(f"  Processing {scene_name}...")
        scene_visualizations[scene_name] = collect_scene_visualizations(
            scene_name, scene_dir
        )

    # Prepare summary statistics
    summary_stats = prepare_summary_statistics(summary_df)
    logger.info(f"  ✓ Prepared summary statistics for {len(summary_stats)} scenes")

    # Prepare template context
    context = {
        'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'scene_names': scene_names,
        'summary_stats': summary_stats,
        'comparison_charts': comparison_charts,
        'scene_visualizations': scene_visualizations,
    }

    # Render template
    logger.info("Rendering HTML template...")
    try:
        html_content = template.render(**context)
    except Exception as e:
        raise RuntimeError(f"Template rendering failed: {e}")

    # Write output file
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
    except Exception as e:
        raise RuntimeError(f"Failed to write output file: {e}")

    file_size_mb = output_path.stat().st_size / (1024 * 1024)

    logger.info("="*80)
    logger.info("✅ Comprehensive HTML Report Generated")
    logger.info(f"   File: {output_path}")
    logger.info(f"   Size: {file_size_mb:.2f} MB")
    logger.info(f"   Scenes: {len(scene_names)}")
    logger.info(f"   Total visualizations: {len(scene_names) * 7 + 3}")
    logger.info("="*80)

    return output_path


if __name__ == "__main__":
    """
    Validation function to test HTML report generation with real LaMAR data.

    Tests:
    1. Run LaMAR experiment and generate individual visualizations
    2. Generate comprehensive HTML report
    3. Verify report file exists and contains expected content
    """
    from .lamar_experiment import run_lamar_experiment
    from .lamar_visualization import (
        generate_lamar_visualizations,
        create_summary_dataframe
    )

    # Setup logging
    logger.add("logs/html_report_test.log", rotation="10 MB")

    # Track validation failures
    all_validation_failures = []
    total_tests = 0

    # Test configuration
    base_dir = Path("datasets/lamar")
    output_dir = Path("test_viz_output/html_report_test")
    scenes = ["CAB", "HGE", "LIN"]

    print("="*80)
    print("HTML Report Generator Validation")
    print("="*80)

    if not base_dir.exists():
        print(f"❌ Dataset not found at {base_dir}")
        sys.exit(1)

    # Test 1: Run LaMAR experiment and generate visualizations
    total_tests += 1
    print(f"\nTest {total_tests}: Running LaMAR experiment and generating visualizations...")
    try:
        results = run_lamar_experiment(scenes, base_dir, output_dir, validate=False)
        viz_paths = generate_lamar_visualizations(results, output_dir)
        summary_df = create_summary_dataframe(results)

        if len(viz_paths.all_figures) == 0:
            all_validation_failures.append("Prerequisite: No individual visualizations generated")
            print("❌ No visualizations generated")
        else:
            print(f"✅ Generated {len(viz_paths.all_figures)} individual visualization files")

    except Exception as e:
        all_validation_failures.append(f"Prerequisite: Exception - {e}")
        print(f"❌ Exception: {e}")
        sys.exit(1)

    # Test 2: Generate comprehensive HTML report
    total_tests += 1
    print(f"\nTest {total_tests}: Generating comprehensive HTML report...")
    try:
        report_path = output_dir / "comprehensive_dashboard.html"
        generated_path = generate_comprehensive_report(viz_paths, summary_df, report_path)

        if not generated_path.exists():
            all_validation_failures.append("Report generation: File not created")
            print("❌ Report file not created")
        else:
            file_size = generated_path.stat().st_size
            if file_size == 0:
                all_validation_failures.append("Report generation: Empty file created")
                print("❌ Empty file created")
            else:
                print(f"✅ Report created: {file_size / (1024*1024):.2f} MB")

    except Exception as e:
        all_validation_failures.append(f"Report generation: Exception - {e}")
        print(f"❌ Exception: {e}")

    # Test 3: Verify HTML content
    total_tests += 1
    print(f"\nTest {total_tests}: Verifying HTML report content...")
    try:
        with open(report_path, 'r', encoding='utf-8') as f:
            html_content = f.read()

        # Check for essential elements
        required_elements = [
            ('<!DOCTYPE html>', 'HTML doctype'),
            ('<title>LaMAR SfM Reconstruction Report</title>', 'Page title'),
            ('Summary Statistics', 'Summary section'),
            ('Cross-Scene Comparisons', 'Comparison section'),
        ]

        missing_elements = []
        for element, description in required_elements:
            if element not in html_content:
                missing_elements.append(description)

        # Check for scene sections
        for scene in scenes:
            if f'{scene} Scene' not in html_content:
                missing_elements.append(f'{scene} scene section')

        if missing_elements:
            all_validation_failures.append(f"Content verification: Missing elements - {', '.join(missing_elements)}")
            print(f"❌ Missing elements: {', '.join(missing_elements)}")
        else:
            print(f"✅ All required HTML elements present")

        # Check for Plotly content
        plotly_count = html_content.count('Plotly.newPlot')
        expected_plotly = len(scenes) * 7 + 3  # 7 per scene + 3 comparisons
        if plotly_count < expected_plotly:
            all_validation_failures.append(f"Content verification: Expected {expected_plotly} Plotly charts, found {plotly_count}")
            print(f"❌ Expected {expected_plotly} Plotly charts, found {plotly_count}")
        else:
            print(f"✅ Found {plotly_count} embedded Plotly visualizations")

    except Exception as e:
        all_validation_failures.append(f"Content verification: Exception - {e}")
        print(f"❌ Exception: {e}")

    # Final validation result
    print("\n" + "="*80)
    if all_validation_failures:
        print(f"❌ VALIDATION FAILED - {len(all_validation_failures)} of {total_tests} tests failed:")
        for failure in all_validation_failures:
            print(f"  - {failure}")
        print("="*80)
        print(f"\nPartial output may be available: {report_path}")
        sys.exit(1)
    else:
        print(f"✅ VALIDATION PASSED - All {total_tests} tests produced expected results")
        print("HTML report generator is validated and ready to use")
        print("="*80)
        print(f"\nComprehensive report: {report_path}")
        print("Open in a web browser to view the interactive dashboard")
        sys.exit(0)
